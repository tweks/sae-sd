{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCEfyBoKRMml"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctPd4idRRMmm"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    !pip install diffusers==0.30.0 transformers accelerate scipy omegaconf dotenv loguru ipywidgets\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyAK9PfKRMmm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import urllib.request\n",
        "\n",
        "from IPython.display import display\n",
        "from transformers import pipeline\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRpvsH4QRMmn"
      },
      "outputs": [],
      "source": [
        "root_dir = Path(os.getcwd()).parent\n",
        "try:\n",
        "    import google.colab\n",
        "    !git clone https://github.com/tweks/sae-sd.git\n",
        "    root_dir = Path(os.path.join(os.getcwd(), 'sae-sd'))\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHoE11YvRMmn"
      },
      "outputs": [],
      "source": [
        "model_url = 'https://github.com/tweks/sae-sd/releases/download/model-v0.0.1/12288_768_TopKReLU_64_False_False_0.0_CC3M_15_train_target_223758458_768.pt'\n",
        "model_path = root_dir/'model'/'data'/os.path.basename(model_url)\n",
        "if not os.path.exists(model_path):\n",
        "    urllib.request.urlretrieve(model_url, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmGaeDoyRMmn"
      },
      "outputs": [],
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(\"stable-diffusion-v1-5/stable-diffusion-v1-5\", torch_dtype=torch.float32)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "pipe = pipe.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CF-yogORMmn"
      },
      "outputs": [],
      "source": [
        "clip = pipeline(\n",
        "   task=\"zero-shot-image-classification\",\n",
        "   model=\"openai/clip-vit-base-patch32\",\n",
        "   torch_dtype=torch.float32,\n",
        "   device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AxOPmxoRMmn"
      },
      "source": [
        "# Standard SD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VgDz9_7WqMW"
      },
      "outputs": [],
      "source": [
        "DEFAULT_SEED = 0\n",
        "try:\n",
        "    import google.colab\n",
        "    DEFAULT_SEED = 26\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EsxqI7sbSQd"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=DEFAULT_SEED):\n",
        "    print(f'Setting seed to {seed}')\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlJeMPMLbZay"
      },
      "outputs": [],
      "source": [
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVkiHPaRRMmn"
      },
      "outputs": [],
      "source": [
        "prompt = \"a photo of an astronaut riding a horse on mars\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbWip5UsRMmo"
      },
      "outputs": [],
      "source": [
        "prompt_embed = pipe.encode_prompt(prompt, device=device, num_images_per_prompt=1, do_classifier_free_guidance=True)[0]\n",
        "prompt_embed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I64iHK4kTUAY"
      },
      "outputs": [],
      "source": [
        "def generate_image(prompt, seed=DEFAULT_SEED):\n",
        "    prompt_embed = pipe.encode_prompt(prompt, device=device, num_images_per_prompt=1, do_classifier_free_guidance=True)[0]\n",
        "    generator = torch.Generator(device).manual_seed(seed)\n",
        "    return pipe(prompt_embeds=prompt_embed, generator=generator).images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-IfTSzf7S8I"
      },
      "source": [
        "## Other seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63AIqlcee2KS"
      },
      "outputs": [],
      "source": [
        "def generate_images(prompt, seed_start, seed_end):\n",
        "    print(f'Generating images for seeds [{seed_start}, {seed_end}]')\n",
        "    for seed in range(seed_start, seed_end + 1):\n",
        "        print(f'Seed: {seed}')\n",
        "        set_seed(seed)\n",
        "        display(generate_image(prompt, seed=seed))\n",
        "    set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZ2-BgYc4hQz"
      },
      "outputs": [],
      "source": [
        "#for seed in range(20, 31):\n",
        "#    print(f\"Seed: {seed}\")\n",
        "#    set_seed(seed)\n",
        "#    display(generate_image(prompt, seed=seed))\n",
        "#set_seed()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk-MRub2RMmo"
      },
      "source": [
        "# Modified SD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbnYzhZCd9qt"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlLXk2GQRMmo"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if str(root_dir) not in sys.path:\n",
        "    sys.path.append(str(root_dir))\n",
        "import json\n",
        "import numpy as np\n",
        "from model.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aahZwb-LRMmo"
      },
      "outputs": [],
      "source": [
        "model, dataset_normalize, dataset_target_norm, dataset_mean = load_model(str(root_dir/\"model/data/12288_768_TopKReLU_64_False_False_0.0_CC3M_15_train_target_223758458_768.pt\"))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "model, dataset_normalize, dataset_target_norm, dataset_mean.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwI6tjfiRMmo"
      },
      "outputs": [],
      "source": [
        "ds_info = json.load(open(root_dir/\"model/data/CC3M_15_train_target_sds_train_dataset_metadata.json\"))\n",
        "ds_info.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQF8_GzzRMmo"
      },
      "outputs": [],
      "source": [
        "dataset_scaling_factor = ds_info[\"scaling_factor\"]\n",
        "lenses = None\n",
        "seq_id = 0\n",
        "seq_len = 0\n",
        "dataset_scaling_factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MFTtM8-RMmo"
      },
      "outputs": [],
      "source": [
        "def process_data(data: np.ndarray | torch.Tensor, idx: int | None=None) -> torch.Tensor:\n",
        "    \"\"\"Process data into the correct format.\"\"\"\n",
        "    X = data.to(torch.float32)\n",
        "    X = X.sub(dataset_mean)\n",
        "    X = X.mul(dataset_scaling_factor)\n",
        "\n",
        "    if lenses is not None and idx is not None:\n",
        "        current_seq_id = idx % seq_len\n",
        "        if current_seq_id != seq_id:\n",
        "            lens = lenses[current_seq_id]\n",
        "            X = lens(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def invert_preprocess(data: torch.Tensor, idx: int | None=None) -> torch.Tensor:\n",
        "    \"\"\"Inverse process data.\"\"\"\n",
        "    if lenses is not None and idx is not None:\n",
        "        current_seq_id = idx % seq_len\n",
        "        if current_seq_id != seq_id:\n",
        "            lens = lenses[current_seq_id]\n",
        "            X = lens.invert(data)\n",
        "        else:\n",
        "            X = data\n",
        "    else:\n",
        "        X = data\n",
        "\n",
        "    X = X.div(dataset_scaling_factor)\n",
        "    X = X.add(dataset_mean)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z28zNoCj7ia"
      },
      "source": [
        "## Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsEm8tebRMmo"
      },
      "outputs": [],
      "source": [
        "prompt_embed_to_sae = prompt_embed.squeeze(0)\n",
        "prompt_embed_to_sae.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDY9eE16RMmo"
      },
      "outputs": [],
      "source": [
        "prompt_embed_to_sae_pre = process_data(prompt_embed_to_sae)\n",
        "prompt_embed_to_sae_post = invert_preprocess(prompt_embed_to_sae_pre)\n",
        "prompt_embed_to_sae_post.shape, prompt_embed_to_sae_post.shape, torch.allclose(prompt_embed_to_sae, prompt_embed_to_sae_post, atol=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concepts"
      ],
      "metadata": {
        "id": "SZ79eCEafkWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokens(prompt, padding='max_length'):\n",
        "    return pipe.tokenizer.convert_ids_to_tokens(pipe.tokenizer.encode(prompt, max_length=77, truncation=True, padding=padding))"
      ],
      "metadata": {
        "id": "0mHHaG3TUaur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjtDwuxtRMmo"
      },
      "outputs": [],
      "source": [
        "concepts = []\n",
        "with open(root_dir/\"model/data/clip_disect_20k.txt\") as f:\n",
        "    concepts = [line.strip() for line in f.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sae_representations(prompt):\n",
        "    num_tokens = len(pipe.tokenizer.convert_ids_to_tokens(pipe.tokenizer.encode(prompt)))\n",
        "    tokens = pipe.tokenizer.convert_ids_to_tokens(pipe.tokenizer.encode(prompt, max_length=77, truncation=True, padding='max_length'))\n",
        "    max_tok_len = max([len(t) for t in tokens])\n",
        "    a = pipe.encode_prompt(prompt, device=device, num_images_per_prompt=1, do_classifier_free_guidance=True)[0]\n",
        "    a = a.squeeze(0)\n",
        "    a_proc = process_data(a)\n",
        "    with torch.no_grad():\n",
        "        _, latents, _ = model.encode(a_proc)\n",
        "    return latents[[0, num_tokens-2, num_tokens-1]]"
      ],
      "metadata": {
        "id": "RNaTGMMhfnam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sae_representations_batch(prompts):\n",
        "    return torch.stack([get_sae_representations(prompt) for prompt in prompts])"
      ],
      "metadata": {
        "id": "cbLBbGXWh0SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_sae_representations('horse')"
      ],
      "metadata": {
        "id": "16dgU2mxhNsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_sae_representations_batch(concepts[:20])"
      ],
      "metadata": {
        "id": "jKEcO6_1iQXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3utOlpekAbo"
      },
      "source": [
        "## New"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_tokens('horse', False)"
      ],
      "metadata": {
        "id": "XvXW5XmGbjV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_tokens('horse')"
      ],
      "metadata": {
        "id": "kBav4nQOVqXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ3KzIHeW7zP"
      },
      "outputs": [],
      "source": [
        "def get_latent_ids(prompt, num_padding=0):\n",
        "    num_tokens = len(pipe.tokenizer.convert_ids_to_tokens(pipe.tokenizer.encode(prompt)))\n",
        "    tokens = pipe.tokenizer.convert_ids_to_tokens(pipe.tokenizer.encode(prompt, max_length=77, truncation=True, padding='max_length'))\n",
        "    max_tok_len = max([len(t) for t in tokens])\n",
        "    a = pipe.encode_prompt(prompt, device=device, num_images_per_prompt=1, do_classifier_free_guidance=True)[0]\n",
        "    a = a.squeeze(0)\n",
        "    a_proc = process_data(a)\n",
        "    with torch.no_grad():\n",
        "        _, latents, _ = model.encode(a_proc)\n",
        "    num_print = min(77, num_tokens+num_padding)\n",
        "    for tok, latent in zip(tokens[:num_print], latents[:num_print]):\n",
        "        nonzero_values = latent[latent != 0]\n",
        "        nonzero_indices = latent.nonzero().squeeze()\n",
        "        sorted_values, sort_indices = torch.sort(nonzero_values, descending=True)\n",
        "        sorted_indices = nonzero_indices[sort_indices]\n",
        "        print(f'{tok}'.ljust(max_tok_len), {v.item():f\"{i.item():.4f}\" for v,i in zip(sorted_indices, sorted_values)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQUb_-CWf180"
      },
      "outputs": [],
      "source": [
        "get_latent_ids('horse')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_latent_ids('horse', 77)"
      ],
      "metadata": {
        "id": "D9zTXM48cVn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-Hj36qKiGhN"
      },
      "outputs": [],
      "source": [
        "get_latent_ids(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y_vYSezeKf_"
      },
      "outputs": [],
      "source": [
        "def generate_modified_image(prompt, sae_latent_ids, scale, seed=DEFAULT_SEED):\n",
        "    prompt_embed = pipe.encode_prompt(prompt, device=device, num_images_per_prompt=1, do_classifier_free_guidance=True)[0]\n",
        "    prompt_embed_to_sae = prompt_embed.squeeze(0)\n",
        "    prompt_embed_to_sae_pre = process_data(prompt_embed_to_sae)\n",
        "    with torch.no_grad():\n",
        "        _, sae_latents, info = model.encode(prompt_embed_to_sae_pre)\n",
        "        prompt_embed_to_sae_reconstructed = model.decode(sae_latents, info)\n",
        "        for sae_latent_id in sae_latent_ids:\n",
        "            sae_latents[:, sae_latent_id] *= scale\n",
        "        prompt_embed_to_sae_reconstructed_modified = model.decode(sae_latents, info)\n",
        "\n",
        "    prompt_embed_to_sae_reconstructed_post = invert_preprocess(prompt_embed_to_sae_reconstructed)\n",
        "    diff = prompt_embed_to_sae - prompt_embed_to_sae_reconstructed_post\n",
        "    prompt_embed_to_sae_reconstructed_post_modified = invert_preprocess(prompt_embed_to_sae_reconstructed_modified)\n",
        "\n",
        "    generator = torch.Generator(device).manual_seed(seed)\n",
        "    return pipe(prompt_embeds=(prompt_embed_to_sae_reconstructed_post_modified + diff).unsqueeze(0), generator=generator).images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFgrqC89ju2u"
      },
      "outputs": [],
      "source": [
        "def generate_modified_images(prompt, sae_latent_ids, scale, seed=DEFAULT_SEED):\n",
        "    print(prompt)\n",
        "    for sae_latent_id in sae_latent_ids:\n",
        "        print(f'SAE latent id: {sae_latent_id}, scale: {scale}')\n",
        "        display(generate_modified_image(prompt, [sae_latent_id], scale, seed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ0wzji_gf2H"
      },
      "outputs": [],
      "source": [
        "original_image = generate_image(prompt)\n",
        "original_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJP2WjzBkA0w"
      },
      "outputs": [],
      "source": [
        "#generate_modified_images(prompt, [12114, 5722, 1962, 3079, 2461, 7928, 5482, 3791], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzUoWb9ffbFj"
      },
      "outputs": [],
      "source": [
        "generate_modified_image(prompt, [9515], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Khi_4p3hliNy"
      },
      "outputs": [],
      "source": [
        "generate_modified_image(prompt, [12214], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Dht5NwNha18"
      },
      "outputs": [],
      "source": [
        "generate_modified_image(prompt, [1825], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mr9A2_hKjSwC"
      },
      "outputs": [],
      "source": [
        "generate_modified_image(prompt, [12214], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpUtA7xNjj-X"
      },
      "outputs": [],
      "source": [
        "generate_modified_image(prompt, [12114, 9515], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__kV8eb_W7zP"
      },
      "outputs": [],
      "source": [
        "generate_modified_image(prompt, [5722], 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK5iHW-_RMmp"
      },
      "outputs": [],
      "source": [
        "original_image\n",
        "labels = [\"an image containing a horse\", \"an image without a horse\"]\n",
        "original_predictions = clip(original_image, candidate_labels=labels)\n",
        "modified_predictions = clip(image_from_embed, candidate_labels=labels)\n",
        "print(\"Original image predictions:\", original_predictions)\n",
        "print(\"Modified image predictions:\", modified_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q08HE4EQRMmp"
      },
      "source": [
        "# SD comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU-jdWUSRMmp"
      },
      "outputs": [],
      "source": [
        "generate_image('a photo of an astronaut on mars')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDrbtY3wRMmp"
      },
      "outputs": [],
      "source": [
        "generate_image('a photo of an astronaut not riding a horse on mars')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rPgACs0RMmp"
      },
      "outputs": [],
      "source": [
        "generate_image('a photo of an astronaut riding a on mars')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K5tgkzWRMmp"
      },
      "source": [
        "# Green"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuIyqG_qRMmp"
      },
      "outputs": [],
      "source": [
        "idx = concepts.index(\"green\")\n",
        "a = pipe.encode_prompt(concepts[idx], device=device, num_images_per_prompt=1, do_classifier_free_guidance=True)[0]\n",
        "a = a.squeeze(0)\n",
        "a_proc = process_data(a)\n",
        "with torch.no_grad():\n",
        "    _, latents, _ = model.encode(a_proc)\n",
        "for latent in latents[1:10]:\n",
        "    nonzero_values = latent[latent != 0]\n",
        "    nonzero_indices = latent.nonzero().squeeze()\n",
        "    sorted_values, sort_indices = torch.sort(nonzero_values, descending=True)\n",
        "    sorted_indices = nonzero_indices[sort_indices]\n",
        "    print(\"Sorted values:\", {v.item():f\"{i.item():.4f}\" for v,i in zip(sorted_indices, sorted_values)})\n",
        "print(\"----------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gx72tiXRMmp"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    _, sae_latents, info = model.encode(prompt_embed_to_sae_pre)\n",
        "    prompt_embed_to_sae_reconstructed = model.decode(sae_latents, info)\n",
        "    print(\"Before modification\", sae_latents[:,2649])\n",
        "    sae_latents[:,2649] = 9\n",
        "    prompt_embed_to_sae_reconstructed_modified = model.decode(sae_latents, info)\n",
        "\n",
        "prompt_embed_to_sae_reconstructed_post = invert_preprocess(prompt_embed_to_sae_reconstructed)\n",
        "diff = prompt_embed_to_sae - prompt_embed_to_sae_reconstructed_post\n",
        "prompt_embed_to_sae_reconstructed_post_modified = invert_preprocess(prompt_embed_to_sae_reconstructed_modified)\n",
        "\n",
        "generator = torch.Generator(device).manual_seed(seed)\n",
        "image_from_embed = pipe(prompt_embeds=(prompt_embed_to_sae_reconstructed_post_modified + diff).unsqueeze(0), generator=generator).images[0]\n",
        "image_from_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-sajMgdRMmp"
      },
      "outputs": [],
      "source": [
        "original_image\n",
        "labels = [\"an image containing green\", \"an image without green\"]\n",
        "original_predictions = clip(original_image, candidate_labels=labels)\n",
        "modified_predictions = clip(image_from_embed, candidate_labels=labels)\n",
        "print(\"Original image predictions:\", original_predictions)\n",
        "print(\"Modified image predictions:\", modified_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MIn4dGRMmq"
      },
      "source": [
        "SAE ids which are not usable when interpeting the model\n",
        "\n",
        "11114 padding connected\n",
        "\n",
        "3678 beginning of the sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSEsZ4WyRMmq"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sae-sd",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}